# infer_task.py
# ğŸ§  BERT ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸ì„ ì´ìš©í•´ í¬ë¡¤ë§ëœ ìƒí’ˆ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” íƒœìŠ¤í¬ ì •ì˜

from task_queue_module.task_queue import celery_app  # Celery ì¸ìŠ¤í„´ìŠ¤ import
from crawler.utils import preprocess_row_dict, preprocess_fallback_title_only        # ì „ì²˜ë¦¬ í•¨ìˆ˜
from model.classify import predict_category          # BERT ì˜ˆì¸¡ í•¨ìˆ˜
from db.mongo_handler import save_classified_product # ê²°ê³¼ë¥¼ DBì— ì €ì¥

# âœ… "inference_queue"ì—ì„œ ì‹¤í–‰ë  íƒœìŠ¤í¬ ì •ì˜
# - í¬ë¡¤ë§ëœ ê²°ê³¼ë¥¼ ë°›ì•„ ì „ì²˜ë¦¬í•˜ê³ , ì˜ˆì¸¡ ëª¨ë¸ì„ í†µí•´ ì¹´í…Œê³ ë¦¬ë¥¼ íŒë‹¨
# - ìµœì¢…ì ìœ¼ë¡œ MongoDBì— ì €ì¥
@celery_app.task(queue="inference_queue", bind=True, autoretry_for=(Exception,), retry_kwargs={"max_retries": 3}, retry_backoff=True)
def process_inference(self, doc_id: str, product: dict, crawled_result: dict | None):
    try:
        if crawled_result is not None:
            processed_text = preprocess_row_dict(crawled_result)
        else:
            processed_text = preprocess_fallback_title_only(product)

        category = predict_category(processed_text)

        # âœ… ì˜ˆì™¸ê°€ ë‚˜ë”ë¼ë„ ì´ê±´ None ë°©ì§€ìš©
        if crawled_result is None:
            crawled_result = {}

        crawled_result['Category'] = category

        save_classified_product(doc_id, product, category)

    except Exception as e:
        print(f"âŒ ë¶„ë¥˜ íƒœìŠ¤í¬ ì‹¤íŒ¨: {e}")
        raise e  # Celeryì— ì˜ˆì™¸ë¥¼ ì•Œë ¤ì¤˜ì•¼ ì¬ì‹œë„ë¨ (autoretry_for ì“°ëŠ” ê²½ìš°)