from fastapi import FastAPI
from pydantic import BaseModel
from selenium import webdriver
from selenium.webdriver.common.by import By
from contextlib import asynccontextmanager
import time
import json

app = FastAPI()

# ‚úÖ Ï†ÑÏó≠ ÎìúÎùºÏù¥Î≤Ñ (FastAPI ÏÑúÎ≤Ñ ÏãúÏûë Ïãú ÏÉùÏÑ±Îê®)
driver = None

# ‚úÖ ÎìúÎùºÏù¥Î≤Ñ ÏÑ§Ï†ï
def start_driver():
    options = webdriver.ChromeOptions()
    options.add_argument('--start-maximized')
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    return webdriver.Chrome(options=options)

# ‚úÖ ÏÑúÎ≤Ñ ÏãúÏûë Ïãú ÎìúÎùºÏù¥Î≤Ñ ÏºúÍ∏∞
@asynccontextmanager
async def lifespan(app: FastAPI):
    global driver
    driver = start_driver()   # ÏÑúÎ≤Ñ ÏãúÏûë Ïãú ÎìúÎùºÏù¥Î≤Ñ Ïã§Ìñâ
    print("‚úÖ ÎìúÎùºÏù¥Î≤Ñ Ïã§ÌñâÎê®")
    yield
    driver.quit()             # ÏÑúÎ≤Ñ Ï¢ÖÎ£å Ïãú ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å
    print("üõë ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£åÎê®")

app = FastAPI(lifespan=lifespan)

# ‚úÖ ÏöîÏ≤≠ ÌòïÏãù
class CrawlRequest(BaseModel):
    url: str

# ‚úÖ ÌÅ¨Î°§ÎßÅ ÏóîÎìúÌè¨Ïù∏Ìä∏
@app.post("/crawl")
def crawl_url(req: CrawlRequest):
    global driver
    try:
        driver.get("https://shopping.naver.com/")
        time.sleep(1)
        driver.get(req.url)
        time.sleep(2)

        product_name, price, detail_info = "", "", {}

        url = req.url
        if "luxury/boutique" in url:
            product_name = driver.find_element(By.CSS_SELECTOR, "#content h3").text.strip()
            price = driver.find_element(By.CSS_SELECTOR, "span._1LY7DqCnwR").text.strip()
            tables = driver.find_elements(By.CSS_SELECTOR, "#INTRODUCE table.TH_yvPweZa")
            for table in tables:
                for row in table.find_elements(By.TAG_NAME, "tr"):
                    ths = row.find_elements(By.CSS_SELECTOR, "th._15qeGNn6Dt")
                    tds = row.find_elements(By.CSS_SELECTOR, "td.jvlKiI0U_y")
                    for th, td in zip(ths, tds):
                        detail_info[th.text.strip()] = td.text.strip()

        elif "smartstore" in url:
            product_name = driver.find_element(By.CSS_SELECTOR, "#content h3").text.strip()
            price = driver.find_element(By.CSS_SELECTOR, "span._1LY7DqCnwR").text.strip()
            tables = driver.find_elements(By.CSS_SELECTOR, "div._copyable > table._1_UiXWHt__")
            for table in tables:
                for row in table.find_elements(By.TAG_NAME, "tr"):
                    ths = row.find_elements(By.CSS_SELECTOR, "th._1iuv6pLHMD")
                    tds = row.find_elements(By.CSS_SELECTOR, "td.ABROiEshTD")
                    for th, td in zip(ths, tds):
                        key = th.text.strip()
                        detail_info[key] = td.text.strip()

        elif "window-products" in url:
            product_name = driver.find_element(By.CSS_SELECTOR, "#content h3").text.strip()
            price = driver.find_element(By.CSS_SELECTOR, "span._1LY7DqCnwR").text.strip()
            tables = driver.find_elements(By.CSS_SELECTOR, "#INTRODUCE table.TH_yvPweZa")
            for table in tables:
                for row in table.find_elements(By.TAG_NAME, "tr"):
                    ths = row.find_elements(By.CSS_SELECTOR, "th._15qeGNn6Dt")
                    tds = row.find_elements(By.CSS_SELECTOR, "td.jvlKiI0U_y")
                    for th, td in zip(ths, tds):
                        detail_info[th.text.strip()] = td.text.strip()

        return {
            "Product_Name": product_name,
            "Price": price,
            "Detail_Info": json.dumps(detail_info, ensure_ascii=False)
        }

    except Exception as e:
        return {"error": str(e)}

# ‚úÖ ÏÑúÎ≤Ñ Ï¢ÖÎ£å Ïãú ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å
@app.on_event("shutdown")
def shutdown_event():
    global driver
    if driver:
        driver.quit()
        print("üõë ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£åÎê®")
